{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2s4kN_QPQVe"
      },
      "source": [
        "# **REINFORCE [Solutions]**\n",
        "\n",
        "<img src=\"https://drive.google.com/thumbnail?id=1sNbFSGUMoRekB-3eZsrjOyK9uo4l7GuG\" alt=\"Robot says hello!\">\n",
        "\n",
        "<hr>\n",
        "\n",
        "### **Part 7**: Reinforcement Learning (from Zero to One)\n",
        "\n",
        "*African Institute for Mathematical Sciences (AIMS), South Africa\n",
        "12 November, 2024*\n",
        "\n",
        "**Arnu Pretorius** - Staff Research Scientist, InstaDeep\n",
        "\n",
        "*Credits*: Adapted from Deep Learning Indaba 2022. Apache License 2.0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EqhIg1odqg0"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r5rvVHi0ZQBf"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt # graph plotting library\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import chex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium\n",
        "!pip install jaxlib\n",
        "!pip install jax\n",
        "!pip install git+https://github.com/deepmind/dm-haiku\n",
        "!pip install gym==0.25\n",
        "!pip install gym[box2d]\n",
        "!pip install optax\n",
        "!pip install matplotlib\n",
        "!pip install chex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9my7TycafVk",
        "outputId": "9a731f0c-f8fd-434e-ac0e-17ce9fe3a7f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.26.4)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (0.4.1)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.33)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from jax) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax) (1.13.1)\n",
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-e0_s_7a8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/dm-haiku /tmp/pip-req-build-e0_s_7a8\n",
            "  Resolved https://github.com/deepmind/dm-haiku to commit 72c6db405ae9450b0e5b0a8d164d92b44d96796d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.14.dev0) (1.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku==0.0.14.dev0)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.14.dev0) (1.26.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.14.dev0) (0.9.0)\n",
            "Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: dm-haiku\n",
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-haiku: filename=dm_haiku-0.0.14.dev0-py3-none-any.whl size=373527 sha256=a5322c46f4c1eab8dd563bd9bf0b69f2e3e87d7f2fa30b07b0ef5c527b21092c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zu6jbe2y/wheels/b1/df/f1/a357fa8f00c36052bdae1e1fd363650c0bd1e8c3959487b6fb\n",
            "Successfully built dm-haiku\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.14.dev0 jmp-0.0.4\n",
            "Collecting gym==0.25\n",
            "  Downloading gym-0.25.0.tar.gz (720 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.25) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.25.0-py3-none-any.whl size=824409 sha256=7aed079d4a4876c3a3400af1407e323135f9f46d2f3fcbf65928b0217bbd0fad\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/3c/33/32d86254a5bd554f5f07759ae1794646e490dd5fa81ebdcda3\n",
            "Successfully built gym\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.25.0\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/dist-packages (from optax) (0.1.87)\n",
            "Requirement already satisfied: jax>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from optax) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from optax) (0.4.33)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from optax) (1.26.4)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.10/dist-packages (from optax) (1.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax) (4.12.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.27->optax) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.27->optax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.27->optax) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.10/dist-packages (0.1.87)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex) (4.12.2)\n",
            "Requirement already satisfied: jax>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from chex) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from chex) (0.4.33)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.10/dist-packages (from chex) (1.26.4)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.27->chex) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.27->chex) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.27->chex) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gwbqggmcRjMy"
      },
      "outputs": [],
      "source": [
        "from shutil import rmtree # deleting directories\n",
        "import random\n",
        "import pickle\n",
        "import collections # useful data structures\n",
        "import numpy as np\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import jax\n",
        "import jax.numpy as jnp # jax numpy\n",
        "import haiku as hk # jax neural network library\n",
        "import optax # jax optimizer library\n",
        "import matplotlib.pyplot as plt # graph plotting library\n",
        "from collections import namedtuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import gymnasium as gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I07EfY1mxY_1"
      },
      "source": [
        "### **Environment (LunarLander-v2)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS7xm0rNxdHe",
        "outputId": "1d0231e4-342b-4d96-c81f-b4aa6c42aa78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial State:: [ 0.00532827  1.4153526   0.5396849   0.19698907 -0.00616739 -0.1222467\n",
            "  0.          0.        ]\n",
            "Environment Obs Space Shape: (8,)\n",
            "Environment action space: Discrete(4)\n",
            "Number of actions: 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create the environment\n",
        "env_name = \"LunarLander-v2\"\n",
        "env = gym.make(env_name)\n",
        "\n",
        "# Reset the environment\n",
        "s_0 = env.reset()[0]\n",
        "print(\"Initial State::\", s_0)\n",
        "\n",
        "# Get environment obs space\n",
        "obs_shape = env.observation_space.shape\n",
        "print(\"Environment Obs Space Shape:\", obs_shape)\n",
        "\n",
        "# Get action space - e.g. discrete or continuous\n",
        "print(f\"Environment action space: {env.action_space}\")\n",
        "\n",
        "# Get num actions\n",
        "num_actions = env.action_space.n\n",
        "print(f\"Number of actions: {num_actions}\")\n",
        "\n",
        "#  Some helper functions\n",
        "\n",
        "# Function to save logs to a file\n",
        "def save_logs(logs, file_name=\"training_logs.txt\"):\n",
        "    with open(file_name, \"a\") as log_file:  # \"a\" mode to append logs if the file already exists\n",
        "        log_file.write(\"\\n\".join(logs) + \"\\n\")\n",
        "\n",
        "# Function to save model parameters\n",
        "def save_model_parameters(params, file_name=\"learned_params.pkl\"):\n",
        "    with open(file_name, \"wb\") as param_file:\n",
        "        pickle.dump(params, param_file)\n",
        "\n",
        "# Function to save the episode returns list\n",
        "def save_episode_returns(returns_list, file_name=\"episode_returns.pkl\"):\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        pickle.dump(returns_list, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEnSjZVESrxc"
      },
      "source": [
        "## **Policy Gradients (PG)**\n",
        "The goal in RL is to find a policy which maximise the expected cummulative reward (return) the agent receives from the environment. As shown in class, we have a wide array of algorithms depending on the representation of the return, denoted $Ψ$. In general then, we can write the RL objective as:\n",
        "\n",
        "$$J(\\pi_\\theta)=\\mathrm{E}_{\\tau\\sim\\pi_\\theta}\\ [Ψ(\\tau)],$$\n",
        "\n",
        "where $\\pi_\\theta$ is a policy parametrised by $\\theta$, $\\mathrm{E}$ means *expectation*, $\\tau$ is shorthand for \"*episode*\", $\\tau\\sim\\pi_\\theta$ is shorthand for \"*episodes sampled using the policy* $\\pi_\\theta$\", and $Ψ(\\tau)$ is a *representation* of the return of episode $\\tau$, which could simply be the return itself, i.e. $Ψ(\\tau) = G(\\tau)$.\n",
        "\n",
        "Then, the goal in RL is to find the parameters $\\theta$ that maximise the function $J(\\pi_\\theta)$. One way to find these parameters is to perform gradient *ascent* on $J(\\pi_\\theta)$ with respect to the parameters $\\theta$:\n",
        "\n",
        "$$\\theta_{k+1}=\\theta_k + \\alpha \\nabla J(\\pi_\\theta)|_{\\theta_{k}},$$\n",
        "\n",
        "where $\\nabla J(\\pi_\\theta)|_{\\theta_{k}}$ is the gradient of the expected return with respect to the policy parameters $\\theta_k$ and $\\alpha$ is the step size. This quantity, $\\nabla J(\\pi_\\theta)$, is also called the **policy gradient** and is very important in RL. If we can compute the policy gradient, then we will have a means by which to directly optimise our policy.\n",
        "\n",
        "As it turns out, as we saw in class, we can compute the policy gradient as follows:\n",
        "\n",
        "\n",
        "$$\\nabla_{\\theta} J(\\pi_{\\theta})=\\underset{\\tau \\sim \\pi_{\\theta}}{\\mathrm{E}}[\\sum_{t=0}^{T} Ψ_t \\nabla_{\\theta} \\log \\pi_{\\theta}(a_{t} \\mid s_{t})]$$\n",
        "\n",
        "Informaly, the policy gradient is equal to the gradient of the log of the probability of the action chosen, multiplied by the (estimated) return of the episode in which the action was taken.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTnTzgtSuy-y"
      },
      "source": [
        "### **REINFORCE**\n",
        "REINFORCE is a simple RL algorithm that uses the policy gradient to find the optimal policy by increasing the probability of choosing actions (reinforcing actions) that tend to lead to high return, as computed directly by $G(\\tau)$.\n",
        "\n",
        "---\n",
        "> **For you!**\n",
        ">\n",
        "> Implement a function that takes the probability of an action and the return of the episode the action was taken in and computes the log of the probability, multiplied by the return.\n",
        "---\n",
        "\n",
        "**Useful functions:**\n",
        "*   `jnp.log`([docs](https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.log.html)) [Note: we have `import jax.numpy as jnp`]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJObUsoUrOyV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_weighted_log_prob(action_prob, episode_return):\n",
        "\n",
        "    # YOUR CODE\n",
        "\n",
        "    log_prob = jnp.log(action_prob)\n",
        "\n",
        "    weighted_log_prob = log_prob * episode_return\n",
        "\n",
        "    # END YOUR CODE\n",
        "\n",
        "    return weighted_log_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZPoTwa1Gbm1",
        "outputId": "37810f1a-fea2-44f4-f214-3e4dbca5f7dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looks good!\n"
          ]
        }
      ],
      "source": [
        "#@title Check your implementation (run me) {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  action_prob = 0.8\n",
        "  episode_return = 100\n",
        "  result = compute_weighted_log_prob(action_prob, episode_return)\n",
        "  if result != -22.314354:\n",
        "    print(\"Oops! Your implementation looks incorrect.\")\n",
        "  else:\n",
        "    print(\"Looks good!\")\n",
        "except Exception as e:\n",
        "    print(\"Oops! Your implementation looks incorrect.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmgW9UJ3tIpl"
      },
      "source": [
        "### **Return**\n",
        "\n",
        "---\n",
        "> **For you!**\n",
        ">\n",
        "> Implement a function that takes a list of all the rewards obtained in an episode and computes the return for each step.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV1Hww8E3dUJ"
      },
      "outputs": [],
      "source": [
        "def compute_returns(rewards, gamma=0.99):\n",
        "    \"\"\"\n",
        "    This function should take a list of rewards as input and\n",
        "    compute the return for each timestep.\n",
        "\n",
        "    EXAMPLE: compute_returns([1,2,3,4]) = [10, 9, 7, 4], if gamma=1\n",
        "\n",
        "    Arguments:\n",
        "        rewards[t]: is the reward at time step t.\n",
        "        gamma: discount factor\n",
        "\n",
        "    -- IMPORTANT: use the default discount to check your implementation\n",
        "\n",
        "    Returns:\n",
        "        returns[t] should be the return at timestep t.\n",
        "    \"\"\"\n",
        "    returns = []\n",
        "    for i in range(len(rewards)):\n",
        "        G = 0\n",
        "        for j in range(i, len(rewards)):\n",
        "            G += (gamma**(j-i))*rewards[j]\n",
        "        returns.append(G)\n",
        "    return returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLVaVRp28YGI",
        "outputId": "cc637d18-8807-45e8-e705-17deef05a9e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looks good!\n"
          ]
        }
      ],
      "source": [
        "#@title Check your implementation (run me) {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  result = compute_returns([1,2,3,4])\n",
        "\n",
        "  if result != [9.801496, 8.8904, 6.96, 4.0]:\n",
        "    print(\"Oops! Your implementation looks incorrect.\")\n",
        "  else:\n",
        "    print(\"Looks good!\")\n",
        "except Exception as e:\n",
        "    print(\"Oops! Your implementation looks incorrect.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IboxN9MS65i5"
      },
      "source": [
        "### **REINFORCE memory**\n",
        "Next we will need to make a new agent memory to store the returns $G_t$ along with the observation $o_t$ and action $a_t$ at every timestep. Below we implemented such a memory module for you. The function `memory.sample()` will return a batch of the last 500 memories. You are welcome to read through the code to try and understand it, but it is not required. Therefore, we hide the code by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhS4V6auRjM3"
      },
      "outputs": [],
      "source": [
        "# NamedTuple to store memory\n",
        "EpisodeReturnsMemory = collections.namedtuple(\"EpisodeReturnsMemory\", [\"obs\", \"action\", \"returns\"])\n",
        "\n",
        "class EpisodeReturnsBuffer:\n",
        "\n",
        "    def __init__(self, num_transitions_to_store=512, batch_size=256):\n",
        "        self.batch_size = batch_size\n",
        "        self.memory_buffer = collections.deque(maxlen=num_transitions_to_store)\n",
        "        self.current_episode_transition_buffer = []\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.current_episode_transition_buffer.append(transition)\n",
        "        done = transition.terminated or transition.truncated\n",
        "        if done:\n",
        "            episode_rewards = []\n",
        "            for t in self.current_episode_transition_buffer:\n",
        "                episode_rewards.append(t.reward)\n",
        "\n",
        "            G = compute_returns(episode_rewards)\n",
        "\n",
        "            for i, t in enumerate(self.current_episode_transition_buffer):\n",
        "                memory = EpisodeReturnsMemory(t.obs, t.action, G[i])\n",
        "                self.memory_buffer.append(memory)\n",
        "\n",
        "            # Reset episode buffer\n",
        "            self.current_episode_transition_buffer = []\n",
        "\n",
        "\n",
        "    def is_ready(self):\n",
        "        return len(self.memory_buffer) >= self.batch_size\n",
        "\n",
        "    def sample(self):\n",
        "        random_memory_sample = random.sample(self.memory_buffer, self.batch_size)\n",
        "\n",
        "        obs_batch, action_batch, returns_batch = zip(*random_memory_sample)\n",
        "\n",
        "        return EpisodeReturnsMemory(\n",
        "            np.stack(obs_batch).astype(\"float32\"),\n",
        "            np.asarray(action_batch).astype(\"int32\"),\n",
        "            np.asarray(returns_batch).astype(\"int32\")\n",
        "        )\n",
        "# Instantiate Memory\n",
        "REINFORCE_memory = EpisodeReturnsBuffer(num_transitions_to_store=512, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idkav_aSYXvz"
      },
      "source": [
        "### **Policy neural network**\n",
        "Next, we will use a simple neural network to aproximate the policy. Our policy neural network will have an input layer that takes the observation as input and passes it through two hidden layers and then outputs one scalar value for each of the possible actions. So, in CartPole the output layer will have size `2`.\n",
        "\n",
        "[Haiku](https://github.com/deepmind/dm-haiku) is a library for implementing neural networks is JAX. Below we have implemented a simple function to make the policy network for you.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2XO7VkORjM4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_policy_network(num_actions: int, layers=[20, 20]) -> hk.Transformed:\n",
        "  \"\"\"Factory for a simple MLP network for the policy.\"\"\"\n",
        "\n",
        "  def policy_network(obs):\n",
        "    network = hk.Sequential(\n",
        "        [\n",
        "            hk.Flatten(),\n",
        "            hk.nets.MLP(layers + [num_actions])\n",
        "        ]\n",
        "    )\n",
        "    return network(obs)\n",
        "\n",
        "  return hk.without_apply_rng(hk.transform(policy_network))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GR2y8FjaG-G"
      },
      "source": [
        "Haiku networks have two important functions you need to know about. The first is the `network.init(<random_key>, <input>)`, which returns a set of random initial parameters. The second method is the `network.apply(<params>, <input>)` which passes an input through the network using the set of parameters provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJrn9o-Vatkw",
        "outputId": "c318a462-e5a5-4707-9f99-36263e81ce58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial params: dict_keys(['mlp/~/linear_0', 'mlp/~/linear_1', 'mlp/~/linear_2'])\n",
            "Policy network output: [ 0.09457228 -0.1857481  -0.22041705  0.00728684]\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "POLICY_NETWORK = make_policy_network(num_actions = num_actions, layers=[28,28])\n",
        "random_key = jax.random.PRNGKey(0) # random key\n",
        "dummy_obs = np.ones(obs_shape, \"float32\")\n",
        "\n",
        "# Initialise parameters\n",
        "REINFORCE_params = POLICY_NETWORK.init(random_key, dummy_obs)\n",
        "print(\"Initial params:\", REINFORCE_params.keys())\n",
        "\n",
        "# Pass input through the network\n",
        "output = POLICY_NETWORK.apply(REINFORCE_params, dummy_obs)\n",
        "print(\"Policy network output:\", output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlouUBvoeunz"
      },
      "source": [
        "The outputs of our policy network are [logits](https://qr.ae/pv4YTe). To convert this into a probability distribution over actions we pass the logits to the [softmax](https://en.wikipedia.org/wiki/Softmax_function) function.\n",
        "\n",
        "### **REINFORCE action selector**\n",
        "\n",
        "---\n",
        "> **For you!**\n",
        ">\n",
        "> Complete the function below which takes a vector of logits and randomly samples an action from a categorical distibution given by the logits.\n",
        "---\n",
        "\n",
        "**Useful functions:**\n",
        "*   `jax.random.categorical` ([docs](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.categorical.html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3Z8DxUmeOGJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample_action(random_key, logits):\n",
        "    return jax.random.categorical(random_key,logits)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5opHJMO0D_Ub",
        "outputId": "7d1a7c2d-9f51-490b-91b3-ab6a8def355f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looks good!\n"
          ]
        }
      ],
      "source": [
        "#@title Check your implementation (run me) {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  random_key = jax.random.PRNGKey(42) # random key\n",
        "  action = sample_action(random_key, np.array([1,2], \"float32\"))\n",
        "  if action != 1:\n",
        "    print(\"Oops! Your implementation looks incorrect.\")\n",
        "  else:\n",
        "    print(\"Looks good!\")\n",
        "except Exception as e:\n",
        "    print(\"Oops! Your implementation looks incorrect.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP5UH87VRjM4"
      },
      "source": [
        "Now we can implement the `REINFORCE_choose_action` function. We will pass the observation through the policy network to compute the logits and then pass the logits to the `sample_action` function to choose and action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJTzrDAZ0Ul5"
      },
      "outputs": [],
      "source": [
        "def REINFORCE_choose_action(key, params, actor_state, obs, evaluation=False):\n",
        "  obs = jnp.expand_dims(obs, axis=0) # add dummy batch dim before passing through network\n",
        "\n",
        "  # Pass obs through policy network to compute logits\n",
        "  logits = POLICY_NETWORK.apply(params, obs)\n",
        "  logits = logits[0] # remove batch dim\n",
        "\n",
        "  # Randomly sample action\n",
        "  sampled_action = sample_action(key, logits)\n",
        "\n",
        "  return sampled_action, actor_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI26SLAb7iRo"
      },
      "source": [
        "Now that we have  implemented the `REINFORCE_choose_action` function, all we have left to do is to make a `REINFORCE_learn` function. The learn function should use the `weighted_log_prob` function we made earlier to compute the policy gradient loss and apply the gradient updates to our neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ALCJESQJ8e"
      },
      "source": [
        "### **Policy gradient loss**\n",
        "\n",
        "---\n",
        "> **For you!**\n",
        ">\n",
        "> Complete the `policy_gradient_loss` function below. The function should compute the action probabilities by passing the `logits` through the softmax function. Then you should extract the probability of the given `action` (using array indexing) and compute the `weighted_log_prob` using the function we made earlier.\n",
        "---\n",
        "\n",
        "**Useful methods:**\n",
        "*   `jax.nn.softmax` ([docs](https://jax.readthedocs.io/en/latest/_autosummary/jax.nn.softmax.html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sUKkqx0RjM4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def policy_gradient_loss(action, logits, returns):\n",
        "\n",
        "  # YOUR CODE\n",
        "  all_action_probs = jax.nn.softmax(logits) # convert logits into probs\n",
        "\n",
        "  action_prob = all_action_probs[action]\n",
        "\n",
        "  weighted_log_prob = compute_weighted_log_prob(action_prob, returns)\n",
        "\n",
        "  # END YOUR CODE\n",
        "\n",
        "  loss = - weighted_log_prob # negative because we want gradient `ascent`\n",
        "\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AMJvau1FsM5",
        "outputId": "199b2463-f2bc-49aa-b3ec-36c789e76500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looks good!\n"
          ]
        }
      ],
      "source": [
        "#@title Check your implementation (run me) {display-mode: \"form\"}\n",
        "\n",
        "try:\n",
        "  result = policy_gradient_loss(1, np.array([1,2], \"float32\"), 10)\n",
        "  if result != 3.1326165:\n",
        "    print(\"Oops! Your implementation looks incorrect.\")\n",
        "  else:\n",
        "    print(\"Looks good!\")\n",
        "except Exception as e:\n",
        "  print(\"Oops! Your implementation looks incorrect.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzuqx1jJrwVx"
      },
      "source": [
        "When we do a policy gradient update step we are going to want to do it using a batch of experience, rather than just a single experience like above. We can use JAX's [vmap](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html#jax.vmap) function to easily make our `policy_gradient_loss` function work on a batch of experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yq4naLURjM4",
        "outputId": "374ca0a4-8754-4a00-8809-5a640d4d3fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy gradient loss on batch: 3.7653565\n"
          ]
        }
      ],
      "source": [
        "def batched_policy_gradient_loss(params, obs_batch, action_batch, returns_batch):\n",
        "    # Get logits by passing observation through network\n",
        "    logits_batch = POLICY_NETWORK.apply(params, obs_batch)\n",
        "\n",
        "    policy_gradient_loss_batch = jax.vmap(policy_gradient_loss)(action_batch, logits_batch, returns_batch) # add batch\n",
        "\n",
        "    # Compute mean loss over batch\n",
        "    mean_policy_gradient_loss = jnp.mean(policy_gradient_loss_batch)\n",
        "\n",
        "    return mean_policy_gradient_loss\n",
        "\n",
        "# TEST\n",
        "obs_batch = np.ones((3, *obs_shape), \"float32\")\n",
        "actions_batch = np.array([1,0,0])\n",
        "returns_batch = np.array([2.3, 4.3, 2.1])\n",
        "\n",
        "loss = batched_policy_gradient_loss(REINFORCE_params, obs_batch, actions_batch, returns_batch)\n",
        "\n",
        "print(\"Policy gradient loss on batch:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDhTH3culwqo"
      },
      "source": [
        "### **Network Optimiser**\n",
        "\n",
        "To apply policy gradient updates to our neural network we will use a JAX library called [Optax](https://github.com/deepmind/optax). Optax has an implementation of the [Adam optimizer](https://www.geeksforgeeks.org/intuition-of-adam-optimizer/) which we can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxXINlMHP5Ic"
      },
      "outputs": [],
      "source": [
        "REINFORCE_OPTIMIZER = optax.adam(0.0001)\n",
        "\n",
        "# Initialise the optimiser\n",
        "REINFORCE_optim_state = REINFORCE_OPTIMIZER.init(REINFORCE_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViENrHOALbCw"
      },
      "source": [
        "Now we have everything we need tp make the `REINFORCE_learn` function. We will store the state of the optimiser in the `learn_state`. We will compute the gradient of the policy gradient loss by using `jax.grad` ([docs](https://jax.readthedocs.io/en/latest/_autosummary/jax.grad.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQr2Uz5ORjM5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# A NamedTuple to store the state of the optimiser\n",
        "REINFORCELearnState = collections.namedtuple(\"LearnerState\", [\"optim_state\"])\n",
        "\n",
        "def REINFORCE_learn(key, params, learner_state, memory):\n",
        "\n",
        "  # Get the policy gradient by using `jax.grad()` on `batched_policy_gradient_loss`\n",
        "  grad_loss = jax.grad(batched_policy_gradient_loss)(params, memory.obs, memory.action, memory.returns)\n",
        "\n",
        "  # Get param updates using gradient and optimizer\n",
        "  updates, new_optim_state = REINFORCE_OPTIMIZER.update(grad_loss, learner_state.optim_state)\n",
        "\n",
        "  # Apply updates to params\n",
        "  params = optax.apply_updates(params, updates)\n",
        "\n",
        "  return params, REINFORCELearnState(new_optim_state) # update learner state\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yHI6H9q0BKf"
      },
      "source": [
        "### **RL Training Loop**\n",
        "As before, we provide the general RL training loop for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDUbuJr30XN6"
      },
      "outputs": [],
      "source": [
        "#@title Training loop (run me) { display-mode: \"form\" }\n",
        "\n",
        "# NamedTuple to store transitions\n",
        "Transition = collections.namedtuple(\"Transition\", [\"obs\", \"action\", \"reward\", \"next_obs\", \"terminated\", \"truncated\"])\n",
        "# Training Loop\n",
        "def run_training_loop(env_name, agent_params, agent_select_action_func,\n",
        "    agent_actor_state=None, agent_learn_func=None, agent_learner_state=None,\n",
        "    agent_memory=None, num_episodes=1000, evaluator_period=100,\n",
        "    evaluation_episodes=10, learn_steps_per_episode=1,\n",
        "    train_every_timestep=False, video_subdir=\"\",):\n",
        "\n",
        "    # Setup Cartpole environment and recorder\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")        # training environment\n",
        "    eval_env = gym.make(env_name, render_mode=\"rgb_array\")   # evaluation environment\n",
        "\n",
        "    # Video dir\n",
        "    video_dir = \"./video\"+\"/\"+video_subdir\n",
        "\n",
        "    # Clear video dir\n",
        "    try:\n",
        "      rmtree(video_dir)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    # Wrap in recorder\n",
        "    env = RecordVideo(env, video_dir+\"/train\", episode_trigger=lambda x: (x % evaluator_period) == 0, disable_logger= True)\n",
        "    eval_env = RecordVideo(eval_env, video_dir+\"/eval\", episode_trigger=lambda x: (x % evaluation_episodes) == 0,disable_logger=True)\n",
        "\n",
        "    # JAX random number generator\n",
        "    rng = hk.PRNGSequence(jax.random.PRNGKey(0))\n",
        "    random.seed(0)\n",
        "\n",
        "    episode_returns = []                     # List to store history of episode returns.\n",
        "    evaluator_episode_returns = []           # List to store history of evaluator returns.\n",
        "    timesteps = 0\n",
        "    for episode in range(num_episodes):\n",
        "\n",
        "        # Reset environment.\n",
        "        obs = env.reset()[0]  # new way to seed the environment\n",
        "\n",
        "        episode_return = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "\n",
        "            # Agent select action.\n",
        "            action, agent_actor_state = agent_select_action_func(\n",
        "                                            next(rng),\n",
        "                                            agent_params,\n",
        "                                            agent_actor_state,\n",
        "                                            np.array(obs)\n",
        "                                        )\n",
        "\n",
        "            # Step environment.\n",
        "            next_obs, reward, terminated, truncated, _ = env.step(int(action))\n",
        "            done = terminated or truncated\n",
        "            # Pack into transition.\n",
        "            transition = Transition(obs, action, reward, next_obs, terminated, truncated)\n",
        "\n",
        "            # Add transition to memory.\n",
        "            if agent_memory: # check if agent has memory\n",
        "              agent_memory.push(transition)\n",
        "\n",
        "            # Add reward to episode return.\n",
        "            episode_return += reward\n",
        "            # Set obs to next obs before next environment step. CRITICAL!!!\n",
        "            obs = next_obs\n",
        "\n",
        "            # Increment timestep counter\n",
        "            timesteps += 1\n",
        "\n",
        "            # Maybe learn every timestep\n",
        "            if train_every_timestep and (timesteps % 4 == 0) and agent_memory and agent_memory.is_ready(): # Make sure memory is ready\n",
        "                # First sample memory and then pass the result to the learn function\n",
        "                memory = agent_memory.sample()\n",
        "                agent_params, agent_learner_state = agent_learn_func(\n",
        "                                                        next(rng),\n",
        "                                                        agent_params,\n",
        "                                                        agent_learner_state,\n",
        "                                                        memory\n",
        "                                                    )# Ma fihimta\n",
        "\n",
        "        episode_returns.append(episode_return)\n",
        "\n",
        "        # At the end of every episode we do a learn step.\n",
        "        if agent_memory and agent_memory.is_ready(): # Make sure memory is ready\n",
        "\n",
        "            for _ in range(learn_steps_per_episode):\n",
        "                # First sample memory and then pass the result to the learn function\n",
        "                memory = agent_memory.sample()\n",
        "                agent_params, agent_learner_state = agent_learn_func(\n",
        "                                                        next(rng),\n",
        "                                                        agent_params,\n",
        "                                                        agent_learner_state,\n",
        "                                                        memory\n",
        "                                                    )\n",
        "\n",
        "        if (episode % evaluator_period) == 0: # Do evaluation\n",
        "\n",
        "            evaluator_episode_return = 0\n",
        "            for eval_episode in range(evaluation_episodes):\n",
        "                obs = eval_env.reset()[0]\n",
        "                done = False\n",
        "                while not done:\n",
        "                    action, _ = agent_select_action_func(\n",
        "                                    next(rng),\n",
        "                                    agent_params,\n",
        "                                    agent_actor_state,\n",
        "                                    np.array(obs),\n",
        "                                    evaluation=True\n",
        "                                )\n",
        "\n",
        "                    obs, reward, terminated, truncated, _ = eval_env.step(int(action))\n",
        "                    done = terminated or truncated\n",
        "\n",
        "                    evaluator_episode_return += reward\n",
        "\n",
        "            evaluator_episode_return /= evaluation_episodes\n",
        "\n",
        "            evaluator_episode_returns.append(evaluator_episode_return)\n",
        "\n",
        "            logs = [\n",
        "                    f\"Episode: {episode}\",\n",
        "                    f\"Episode Return: {episode_return}\",\n",
        "                    f\"Average Episode Return: {np.mean(episode_returns[-20:])}\",\n",
        "                    f\"Evaluator Episode Return: {evaluator_episode_return}\"\n",
        "            ]\n",
        "\n",
        "            print(*logs, sep=\"\\t\") # Print the logs\n",
        "\n",
        "    env.close()\n",
        "    eval_env.close()\n",
        "\n",
        "    return episode_returns, evaluator_episode_returns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5an3U2NhRKgG"
      },
      "source": [
        "### **REINFORCE training loop**\n",
        "Now we can train our REINFORCE agent by putting everything together using the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RS6ZNpJ0jNv"
      },
      "outputs": [],
      "source": [
        "# JIT the choose_action and learn functions for more speed\n",
        "REINFORCE_learn_jit = jax.jit(REINFORCE_learn)\n",
        "REINFORCE_choose_action_jit = jax.jit(REINFORCE_choose_action)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "vioIcVGsRjM5",
        "outputId": "644cab00-f919-47e6-c843-d6b176c9d5bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training. This may take a few minutes to complete.\n",
            "Episode: 0\tEpisode Return: -121.08498796864944\tAverage Episode Return: -121.08498796864944\tEvaluator Episode Return: -105.35446912086941\n",
            "Episode: 100\tEpisode Return: -20.707295921905967\tAverage Episode Return: -128.58202973174798\tEvaluator Episode Return: -109.18754706993502\n",
            "Episode: 200\tEpisode Return: -149.8053946254915\tAverage Episode Return: -144.56406095715133\tEvaluator Episode Return: -117.81699199649663\n",
            "Episode: 300\tEpisode Return: -119.25246544701695\tAverage Episode Return: -153.87939984172186\tEvaluator Episode Return: -87.38993569624651\n",
            "Episode: 400\tEpisode Return: -39.76637500893885\tAverage Episode Return: -118.18625619102951\tEvaluator Episode Return: -122.17918955402556\n",
            "Episode: 500\tEpisode Return: -118.71564718537614\tAverage Episode Return: -121.92568525198631\tEvaluator Episode Return: -109.04101234361629\n",
            "Episode: 600\tEpisode Return: -70.53297886180232\tAverage Episode Return: -131.21156853035006\tEvaluator Episode Return: -117.03315153756316\n",
            "Episode: 700\tEpisode Return: -107.13430491722194\tAverage Episode Return: -120.58670044421967\tEvaluator Episode Return: -154.73071409776702\n",
            "Episode: 800\tEpisode Return: -87.41776939129518\tAverage Episode Return: -113.69303189123248\tEvaluator Episode Return: -132.1462469848517\n",
            "Episode: 900\tEpisode Return: -129.63096328539257\tAverage Episode Return: -137.02140403733398\tEvaluator Episode Return: -157.38509344814184\n",
            "Episode: 1000\tEpisode Return: -110.7848022336364\tAverage Episode Return: -109.18549232118055\tEvaluator Episode Return: -114.18894514566298\n",
            "Episode: 1100\tEpisode Return: -85.7279309778789\tAverage Episode Return: -147.66036546230526\tEvaluator Episode Return: -133.13828085833023\n",
            "Episode: 1200\tEpisode Return: -89.5457974241628\tAverage Episode Return: -146.6222046964528\tEvaluator Episode Return: -118.5264151719754\n",
            "Episode: 1300\tEpisode Return: -98.69967537060111\tAverage Episode Return: -128.81805627832435\tEvaluator Episode Return: -102.58747068338884\n",
            "Episode: 1400\tEpisode Return: -56.349949114415956\tAverage Episode Return: -108.144213117256\tEvaluator Episode Return: -88.31732742192494\n",
            "Episode: 1500\tEpisode Return: -102.29887821973992\tAverage Episode Return: -98.82346811355589\tEvaluator Episode Return: -92.24547515658568\n",
            "Episode: 1600\tEpisode Return: -131.70904485771072\tAverage Episode Return: -115.26030587087334\tEvaluator Episode Return: -124.03369166479372\n",
            "Episode: 1700\tEpisode Return: -87.87276497296477\tAverage Episode Return: -121.41914636768419\tEvaluator Episode Return: -84.93609511493236\n",
            "Episode: 1800\tEpisode Return: -122.11244780728464\tAverage Episode Return: -93.17392289310183\tEvaluator Episode Return: -99.22606716962679\n",
            "Episode: 1900\tEpisode Return: -58.52970879064017\tAverage Episode Return: -112.39567662402992\tEvaluator Episode Return: -58.17597429295067\n",
            "Episode: 2000\tEpisode Return: -25.131748091484454\tAverage Episode Return: -109.14278050989171\tEvaluator Episode Return: -79.53533535299356\n",
            "Episode: 2100\tEpisode Return: -6.790697788111274\tAverage Episode Return: -62.24639799178742\tEvaluator Episode Return: -97.02350597054053\n",
            "Episode: 2200\tEpisode Return: -105.76604325865065\tAverage Episode Return: -109.73367081723704\tEvaluator Episode Return: -115.51360187112951\n",
            "Episode: 2300\tEpisode Return: -59.36228358184256\tAverage Episode Return: -55.651203664414695\tEvaluator Episode Return: -66.58413931219594\n",
            "Episode: 2400\tEpisode Return: -167.6173152219767\tAverage Episode Return: -72.6122372915057\tEvaluator Episode Return: -86.76796138703546\n",
            "Episode: 2500\tEpisode Return: -339.09494690041913\tAverage Episode Return: -107.47455163995838\tEvaluator Episode Return: -122.78567173745826\n",
            "Episode: 2600\tEpisode Return: -66.9119955247726\tAverage Episode Return: -74.99473372382916\tEvaluator Episode Return: -108.458290832996\n",
            "Episode: 2700\tEpisode Return: -65.31291522273311\tAverage Episode Return: -95.39644183705768\tEvaluator Episode Return: -51.95682112408524\n",
            "Episode: 2800\tEpisode Return: -11.134019914555765\tAverage Episode Return: -82.8476526943278\tEvaluator Episode Return: -61.228592013048775\n",
            "Episode: 2900\tEpisode Return: -217.60868579023673\tAverage Episode Return: -110.53813717084097\tEvaluator Episode Return: -112.12946287493335\n",
            "Episode: 3000\tEpisode Return: -71.76105259805726\tAverage Episode Return: -59.94127199819862\tEvaluator Episode Return: -58.12253694997162\n",
            "Episode: 3100\tEpisode Return: -79.81340093253982\tAverage Episode Return: -53.003173256766345\tEvaluator Episode Return: -86.89403265901429\n",
            "Episode: 3200\tEpisode Return: 2.531837210067053\tAverage Episode Return: -75.89900359417807\tEvaluator Episode Return: -70.19671870000354\n",
            "Episode: 3300\tEpisode Return: -16.541587043253728\tAverage Episode Return: -21.88612601037955\tEvaluator Episode Return: -10.916664461935971\n",
            "Episode: 3400\tEpisode Return: 11.417692818201871\tAverage Episode Return: -45.80038563607638\tEvaluator Episode Return: -27.022566785377865\n",
            "Episode: 3500\tEpisode Return: -24.38525871773581\tAverage Episode Return: -66.02522618187021\tEvaluator Episode Return: -32.122300226139245\n",
            "Episode: 3600\tEpisode Return: -19.614383535170333\tAverage Episode Return: -18.210327663276757\tEvaluator Episode Return: -8.319423864111677\n",
            "Episode: 3700\tEpisode Return: -47.48476930567399\tAverage Episode Return: -9.602837359864656\tEvaluator Episode Return: -38.34095412826157\n",
            "Episode: 3800\tEpisode Return: 6.907606044601458\tAverage Episode Return: -14.391056723870651\tEvaluator Episode Return: -76.4562765263751\n",
            "Episode: 3900\tEpisode Return: 4.239732264046296\tAverage Episode Return: -14.67743114075929\tEvaluator Episode Return: -31.159033978455447\n",
            "Episode: 4000\tEpisode Return: 5.210975359300114\tAverage Episode Return: -5.934095102166272\tEvaluator Episode Return: -19.17389875485735\n",
            "Episode: 4100\tEpisode Return: -11.735729145953044\tAverage Episode Return: -11.851389895992344\tEvaluator Episode Return: 0.29809030683948096\n",
            "Episode: 4200\tEpisode Return: -14.647357112319426\tAverage Episode Return: 4.881188146682469\tEvaluator Episode Return: -3.814743217582926\n",
            "Episode: 4300\tEpisode Return: 5.289603827826184\tAverage Episode Return: -15.806188657236666\tEvaluator Episode Return: 13.228493412509465\n",
            "Episode: 4400\tEpisode Return: -13.211327070498982\tAverage Episode Return: -30.68070858348487\tEvaluator Episode Return: -11.71444013056655\n",
            "Episode: 4500\tEpisode Return: 31.603409963443514\tAverage Episode Return: -23.54466612255279\tEvaluator Episode Return: 10.327165617717094\n",
            "Episode: 4600\tEpisode Return: 34.19903474814945\tAverage Episode Return: -18.87703411562594\tEvaluator Episode Return: -20.63267171576216\n",
            "Episode: 4700\tEpisode Return: 67.56876345675605\tAverage Episode Return: 8.27821256173485\tEvaluator Episode Return: -54.98127315503124\n",
            "Episode: 4800\tEpisode Return: -167.27021404654556\tAverage Episode Return: -4.922545419691397\tEvaluator Episode Return: -9.616801715873999\n",
            "Episode: 4900\tEpisode Return: -12.226074662973469\tAverage Episode Return: -13.886093955224478\tEvaluator Episode Return: -33.83833617354897\n",
            "Episode: 5000\tEpisode Return: -72.28799669126393\tAverage Episode Return: -4.450243845926449\tEvaluator Episode Return: -6.451546834937079\n",
            "Episode: 5100\tEpisode Return: 35.886763150655526\tAverage Episode Return: -0.5188885757377033\tEvaluator Episode Return: -6.173042304014483\n",
            "Episode: 5200\tEpisode Return: 14.39425847550822\tAverage Episode Return: 14.641972345281971\tEvaluator Episode Return: 7.8387773921929185\n",
            "Episode: 5300\tEpisode Return: 2.1742884872442882\tAverage Episode Return: 10.736006429189747\tEvaluator Episode Return: 26.79031284760443\n",
            "Episode: 5400\tEpisode Return: 8.016233876358175\tAverage Episode Return: 12.63923031182662\tEvaluator Episode Return: 19.422524360092257\n",
            "Episode: 5500\tEpisode Return: 58.96100991596499\tAverage Episode Return: 3.1391235731274434\tEvaluator Episode Return: 21.21361221141246\n",
            "Episode: 5600\tEpisode Return: 57.73414104496257\tAverage Episode Return: 21.367217759652625\tEvaluator Episode Return: 1.6092559464318874\n",
            "Episode: 5700\tEpisode Return: -7.195892542677832\tAverage Episode Return: -17.575971363667673\tEvaluator Episode Return: 14.155316828804057\n",
            "Episode: 5800\tEpisode Return: 34.206324278969475\tAverage Episode Return: 28.590285553349883\tEvaluator Episode Return: -5.546675187494205\n",
            "Episode: 5900\tEpisode Return: 36.312555701727554\tAverage Episode Return: -8.827657617295632\tEvaluator Episode Return: 30.175077165816145\n",
            "Episode: 6000\tEpisode Return: -0.3723523057094411\tAverage Episode Return: 35.30308700879818\tEvaluator Episode Return: 45.07694671502786\n",
            "Episode: 6100\tEpisode Return: 42.303328687045294\tAverage Episode Return: 22.77343059425919\tEvaluator Episode Return: 18.2183774120241\n",
            "Episode: 6200\tEpisode Return: 44.085129231617785\tAverage Episode Return: 30.495714502469458\tEvaluator Episode Return: 55.56650463560493\n",
            "Episode: 6300\tEpisode Return: 8.220719565763364\tAverage Episode Return: 36.12735145550009\tEvaluator Episode Return: 38.62697463737037\n",
            "Episode: 6400\tEpisode Return: 44.44914506897291\tAverage Episode Return: 22.546336407293403\tEvaluator Episode Return: 58.762991039806174\n",
            "Episode: 6500\tEpisode Return: 96.46734178265588\tAverage Episode Return: 14.739382603384945\tEvaluator Episode Return: 17.45651902025496\n",
            "Episode: 6600\tEpisode Return: 59.830495731919626\tAverage Episode Return: 51.476439102679514\tEvaluator Episode Return: 43.722958002381255\n",
            "Episode: 6700\tEpisode Return: 21.600536677138493\tAverage Episode Return: 20.281241476783737\tEvaluator Episode Return: 36.64042908560346\n",
            "Episode: 6800\tEpisode Return: -163.76200724296257\tAverage Episode Return: 34.90121578205154\tEvaluator Episode Return: 63.51210945525096\n",
            "Episode: 6900\tEpisode Return: 59.55364409665131\tAverage Episode Return: 61.55896971546857\tEvaluator Episode Return: 44.376010590644256\n",
            "Episode: 7000\tEpisode Return: 82.11440577586004\tAverage Episode Return: 39.949632909542466\tEvaluator Episode Return: 52.94837263585207\n",
            "Episode: 7100\tEpisode Return: 40.021942734379294\tAverage Episode Return: 61.42076291533321\tEvaluator Episode Return: 49.03405377068678\n",
            "Episode: 7200\tEpisode Return: 48.36156445484942\tAverage Episode Return: 62.33468242438234\tEvaluator Episode Return: 95.20659342076178\n",
            "Episode: 7300\tEpisode Return: 111.63364643633308\tAverage Episode Return: 76.30823743079631\tEvaluator Episode Return: 76.27505585102296\n",
            "Episode: 7400\tEpisode Return: 18.780229446769653\tAverage Episode Return: 73.20825435324488\tEvaluator Episode Return: 72.81153330280809\n",
            "Episode: 7500\tEpisode Return: 76.76174097069236\tAverage Episode Return: 68.04707905067069\tEvaluator Episode Return: 74.58429735409837\n",
            "Episode: 7600\tEpisode Return: 105.13227531736584\tAverage Episode Return: 87.28957008460611\tEvaluator Episode Return: 57.01558953154368\n",
            "Episode: 7700\tEpisode Return: 92.26568969430176\tAverage Episode Return: 82.29657275185545\tEvaluator Episode Return: 96.7649503659994\n",
            "Episode: 7800\tEpisode Return: 108.50286198743687\tAverage Episode Return: 104.18442217507456\tEvaluator Episode Return: 72.94444555630594\n",
            "Episode: 7900\tEpisode Return: 80.19222107773086\tAverage Episode Return: 92.08143873109663\tEvaluator Episode Return: 86.98586779448915\n",
            "Episode: 8000\tEpisode Return: 122.60360700003275\tAverage Episode Return: 97.19476472133854\tEvaluator Episode Return: 111.78344653116187\n",
            "Episode: 8100\tEpisode Return: 111.60818763633809\tAverage Episode Return: 90.24423766936084\tEvaluator Episode Return: 107.2842822262194\n",
            "Episode: 8200\tEpisode Return: 103.69448087760847\tAverage Episode Return: 104.08359833308616\tEvaluator Episode Return: 112.55274266765142\n",
            "Episode: 8300\tEpisode Return: 104.11616137583532\tAverage Episode Return: 86.41041078014953\tEvaluator Episode Return: 69.06316977550168\n",
            "Episode: 8400\tEpisode Return: 55.3876415869386\tAverage Episode Return: 64.72767776419963\tEvaluator Episode Return: 36.13008885555653\n",
            "Episode: 8500\tEpisode Return: 135.55701183496612\tAverage Episode Return: 106.7847793104427\tEvaluator Episode Return: 106.91289201936607\n",
            "Episode: 8600\tEpisode Return: 21.082969713814293\tAverage Episode Return: 95.37415515146385\tEvaluator Episode Return: 90.6168837201125\n",
            "Episode: 8700\tEpisode Return: 119.81549875257528\tAverage Episode Return: 110.90788710968329\tEvaluator Episode Return: 106.52110990330955\n",
            "Episode: 8800\tEpisode Return: 97.26993585923074\tAverage Episode Return: 111.28368733556627\tEvaluator Episode Return: 100.60207873382011\n",
            "Episode: 8900\tEpisode Return: 107.3842224412101\tAverage Episode Return: 76.73311702975343\tEvaluator Episode Return: 97.16441347982023\n",
            "Episode: 9000\tEpisode Return: 113.61597781010569\tAverage Episode Return: 101.22551730799553\tEvaluator Episode Return: 85.82483013822652\n",
            "Episode: 9100\tEpisode Return: 126.0100390973902\tAverage Episode Return: 70.68526362562878\tEvaluator Episode Return: 92.12952385251795\n",
            "Episode: 9200\tEpisode Return: 78.8629706851108\tAverage Episode Return: 102.77379853657746\tEvaluator Episode Return: 98.90098731676774\n",
            "Episode: 9300\tEpisode Return: 87.21457595834288\tAverage Episode Return: 107.11819915898954\tEvaluator Episode Return: 100.52781528662109\n",
            "Episode: 9400\tEpisode Return: 103.44531490289893\tAverage Episode Return: 99.17023180383565\tEvaluator Episode Return: 116.03010281586145\n",
            "Episode: 9500\tEpisode Return: 145.6395259165491\tAverage Episode Return: 110.2440950244364\tEvaluator Episode Return: 122.1059635514662\n",
            "Episode: 9600\tEpisode Return: 144.65023241393334\tAverage Episode Return: 111.92729732814789\tEvaluator Episode Return: 75.2782920118645\n",
            "Episode: 9700\tEpisode Return: 105.2810203148934\tAverage Episode Return: 101.58197596871409\tEvaluator Episode Return: 77.314710958232\n",
            "Episode: 9800\tEpisode Return: 115.17566968369867\tAverage Episode Return: 104.06756210829671\tEvaluator Episode Return: 119.19839759333804\n",
            "Episode: 9900\tEpisode Return: -30.283243610626116\tAverage Episode Return: 75.79385154890522\tEvaluator Episode Return: 110.59004067403853\n",
            "Episode: 10000\tEpisode Return: 132.460034183372\tAverage Episode Return: 104.72391886906651\tEvaluator Episode Return: 69.71986895938205\n",
            "Episode: 10100\tEpisode Return: 135.1911382832423\tAverage Episode Return: 113.24178205653777\tEvaluator Episode Return: 113.00739777533359\n",
            "Episode: 10200\tEpisode Return: 141.64858681904676\tAverage Episode Return: 122.65071939441354\tEvaluator Episode Return: 114.48158710677043\n",
            "Episode: 10300\tEpisode Return: 135.11741502659567\tAverage Episode Return: 108.51395438782879\tEvaluator Episode Return: 105.2278214483018\n",
            "Episode: 10400\tEpisode Return: 133.5869587982273\tAverage Episode Return: 130.1947296930127\tEvaluator Episode Return: 102.60680558465381\n",
            "Episode: 10500\tEpisode Return: 108.7468878106119\tAverage Episode Return: 109.25697768699813\tEvaluator Episode Return: 125.80037245552005\n",
            "Episode: 10600\tEpisode Return: 119.58510325269555\tAverage Episode Return: 94.798049903023\tEvaluator Episode Return: 105.9189326270739\n",
            "Episode: 10700\tEpisode Return: 136.67743107330628\tAverage Episode Return: 117.3147585371236\tEvaluator Episode Return: 97.791187043438\n",
            "Episode: 10800\tEpisode Return: 105.27273919330744\tAverage Episode Return: 106.30074569695375\tEvaluator Episode Return: 101.28836156540491\n",
            "Episode: 10900\tEpisode Return: 41.8648014767752\tAverage Episode Return: 98.79834304364363\tEvaluator Episode Return: 104.35118208860249\n",
            "Episode: 11000\tEpisode Return: 95.9969539331453\tAverage Episode Return: 103.0934463275153\tEvaluator Episode Return: 107.18890687857215\n",
            "Episode: 11100\tEpisode Return: 115.57703446462509\tAverage Episode Return: 114.67369630480582\tEvaluator Episode Return: 115.54740980235843\n",
            "Episode: 11200\tEpisode Return: 103.4832392632047\tAverage Episode Return: 123.05119818326341\tEvaluator Episode Return: 123.57525732902388\n",
            "Episode: 11300\tEpisode Return: 142.921079258005\tAverage Episode Return: 111.90604400498853\tEvaluator Episode Return: 116.04256418012827\n",
            "Episode: 11400\tEpisode Return: 123.83201015135226\tAverage Episode Return: 99.08338733912271\tEvaluator Episode Return: 124.71986689381508\n",
            "Episode: 11500\tEpisode Return: 103.75719337538527\tAverage Episode Return: 119.2500021413492\tEvaluator Episode Return: 117.38665022556128\n",
            "Episode: 11600\tEpisode Return: 108.97707191457557\tAverage Episode Return: 111.81153882613744\tEvaluator Episode Return: 109.22843646886027\n",
            "Episode: 11700\tEpisode Return: 131.88454229656787\tAverage Episode Return: 119.32930033730099\tEvaluator Episode Return: 115.41505613419\n",
            "Episode: 11800\tEpisode Return: 101.8759665842133\tAverage Episode Return: 120.4154437693117\tEvaluator Episode Return: 121.65759513278597\n",
            "Episode: 11900\tEpisode Return: 110.75948541288064\tAverage Episode Return: 115.65826994519884\tEvaluator Episode Return: 130.6142505217196\n",
            "Episode: 12000\tEpisode Return: 79.10876005657076\tAverage Episode Return: 112.75164821163753\tEvaluator Episode Return: 121.11800148049201\n",
            "Episode: 12100\tEpisode Return: 97.80228284296793\tAverage Episode Return: 112.22477516619101\tEvaluator Episode Return: 116.07256007157548\n",
            "Episode: 12200\tEpisode Return: 123.49019245239359\tAverage Episode Return: 128.0684830659184\tEvaluator Episode Return: 140.3335296992918\n",
            "Episode: 12300\tEpisode Return: 163.64194603872016\tAverage Episode Return: 143.49327612969745\tEvaluator Episode Return: 161.10125853648793\n",
            "Episode: 12400\tEpisode Return: 113.59444541072078\tAverage Episode Return: 118.86997696729233\tEvaluator Episode Return: 132.62957386584878\n",
            "Episode: 12500\tEpisode Return: 162.14264149987923\tAverage Episode Return: 134.67960925746007\tEvaluator Episode Return: 132.28195068332573\n",
            "Episode: 12600\tEpisode Return: 114.2723670400354\tAverage Episode Return: 131.0205949656892\tEvaluator Episode Return: 133.38294225177873\n",
            "Episode: 12700\tEpisode Return: 118.40531585941667\tAverage Episode Return: 121.7408697466727\tEvaluator Episode Return: 114.32429451253385\n",
            "Episode: 12800\tEpisode Return: 111.37604596030579\tAverage Episode Return: 114.2665949306366\tEvaluator Episode Return: 101.05743378009569\n",
            "Episode: 12900\tEpisode Return: 117.62493370353192\tAverage Episode Return: 112.26875950253074\tEvaluator Episode Return: 116.91133406772649\n",
            "Episode: 13000\tEpisode Return: 104.9107850277929\tAverage Episode Return: 121.67874841384238\tEvaluator Episode Return: 117.72602559790198\n",
            "Episode: 13100\tEpisode Return: 117.55355933794401\tAverage Episode Return: 100.58597480702772\tEvaluator Episode Return: 112.97125370668975\n",
            "Episode: 13200\tEpisode Return: 87.15409237401934\tAverage Episode Return: 115.9438473135724\tEvaluator Episode Return: 122.84822935948091\n",
            "Episode: 13300\tEpisode Return: 143.90714510658975\tAverage Episode Return: 119.5305561102017\tEvaluator Episode Return: 128.13614003811935\n",
            "Episode: 13400\tEpisode Return: 42.574857378331984\tAverage Episode Return: 85.95437028455348\tEvaluator Episode Return: 83.77560084615665\n",
            "Episode: 13500\tEpisode Return: 273.4532636328993\tAverage Episode Return: 225.252405953048\tEvaluator Episode Return: 213.51211740952175\n",
            "Episode: 13600\tEpisode Return: 247.9474371760836\tAverage Episode Return: 235.83022238058206\tEvaluator Episode Return: 256.1023589751231\n",
            "Episode: 13700\tEpisode Return: 238.16394643965924\tAverage Episode Return: 195.86627542267428\tEvaluator Episode Return: 239.3011650815616\n",
            "Episode: 13800\tEpisode Return: 292.53348208339213\tAverage Episode Return: 247.1845737565771\tEvaluator Episode Return: 195.73051087816776\n",
            "Episode: 13900\tEpisode Return: 303.3901009554563\tAverage Episode Return: 239.2203046493064\tEvaluator Episode Return: 199.87763256500006\n",
            "Episode: 14000\tEpisode Return: 255.29353537682104\tAverage Episode Return: 206.53290593900337\tEvaluator Episode Return: 227.48770013886514\n",
            "Episode: 14100\tEpisode Return: 236.54893276750428\tAverage Episode Return: 212.73800252262248\tEvaluator Episode Return: 252.93311891384784\n",
            "Episode: 14200\tEpisode Return: 280.64959282437707\tAverage Episode Return: 225.49584030567885\tEvaluator Episode Return: 234.2186813765405\n",
            "Episode: 14300\tEpisode Return: 253.73271467480853\tAverage Episode Return: 238.2991120558751\tEvaluator Episode Return: 227.22614485572558\n",
            "Episode: 14400\tEpisode Return: 210.88783579915633\tAverage Episode Return: 237.56437508329054\tEvaluator Episode Return: 257.4923233362367\n",
            "Episode: 14500\tEpisode Return: 230.24671836332095\tAverage Episode Return: 234.4809970514081\tEvaluator Episode Return: 243.4267848142449\n",
            "Episode: 14600\tEpisode Return: 204.93379826730694\tAverage Episode Return: 218.2997014230782\tEvaluator Episode Return: 250.4778368958157\n",
            "Episode: 14700\tEpisode Return: 266.58760148247455\tAverage Episode Return: 244.97266301979775\tEvaluator Episode Return: 245.50086851034848\n",
            "Episode: 14800\tEpisode Return: 228.04847062016412\tAverage Episode Return: 242.95774271585597\tEvaluator Episode Return: 235.10710657232204\n",
            "Episode: 14900\tEpisode Return: 237.42356693547836\tAverage Episode Return: 238.21063205344345\tEvaluator Episode Return: 197.61135710523425\n",
            "Episode: 15000\tEpisode Return: 249.94042213462635\tAverage Episode Return: 270.5271822854896\tEvaluator Episode Return: 269.1296389489635\n",
            "Episode: 15100\tEpisode Return: 285.13369794142096\tAverage Episode Return: 210.79571574906353\tEvaluator Episode Return: 225.0827943093331\n",
            "Episode: 15200\tEpisode Return: 291.7078309090343\tAverage Episode Return: 227.96451728592737\tEvaluator Episode Return: 219.2091590080873\n",
            "Episode: 15300\tEpisode Return: 275.2197349433195\tAverage Episode Return: 228.22940574380237\tEvaluator Episode Return: 235.7510881458822\n",
            "Episode: 15400\tEpisode Return: 261.0157366086658\tAverage Episode Return: 231.90491384135004\tEvaluator Episode Return: 253.49222708062698\n",
            "Episode: 15500\tEpisode Return: 237.2226939447744\tAverage Episode Return: 229.65478060352612\tEvaluator Episode Return: 269.56864965178636\n",
            "Episode: 15600\tEpisode Return: 268.3848034819131\tAverage Episode Return: 239.83714686005555\tEvaluator Episode Return: 249.1644413811028\n",
            "Episode: 15700\tEpisode Return: 254.59626526780283\tAverage Episode Return: 240.17302526306875\tEvaluator Episode Return: 257.9750752670678\n",
            "Episode: 15800\tEpisode Return: 222.68683500242247\tAverage Episode Return: 249.90114746938292\tEvaluator Episode Return: 229.08692662835023\n",
            "Episode: 15900\tEpisode Return: 260.12474773790706\tAverage Episode Return: 251.4254696524762\tEvaluator Episode Return: 244.8460133496134\n",
            "Episode: 16000\tEpisode Return: 233.2644336487359\tAverage Episode Return: 222.02815888882486\tEvaluator Episode Return: 247.0724997041134\n",
            "Episode: 16100\tEpisode Return: 280.30149904616474\tAverage Episode Return: 221.48578893933762\tEvaluator Episode Return: 184.12129155114155\n",
            "Episode: 16200\tEpisode Return: 272.3541332967832\tAverage Episode Return: 244.27604587471677\tEvaluator Episode Return: 265.98559074432393\n",
            "Episode: 16300\tEpisode Return: 81.49525676221683\tAverage Episode Return: 193.592504026179\tEvaluator Episode Return: 245.27417761069196\n",
            "Episode: 16400\tEpisode Return: 268.5335652694227\tAverage Episode Return: 225.93898263935762\tEvaluator Episode Return: 206.2499355369987\n",
            "Episode: 16500\tEpisode Return: 67.51373251575234\tAverage Episode Return: 187.905886139218\tEvaluator Episode Return: 224.1658767483686\n",
            "Episode: 16600\tEpisode Return: 233.54931666929593\tAverage Episode Return: 225.01702018209184\tEvaluator Episode Return: 274.1136736971788\n",
            "Episode: 16700\tEpisode Return: 297.35103458897544\tAverage Episode Return: 222.4442682378297\tEvaluator Episode Return: 186.41942224604736\n",
            "Episode: 16800\tEpisode Return: 281.0791227504619\tAverage Episode Return: 217.66622140824816\tEvaluator Episode Return: 196.99081197435143\n",
            "Episode: 16900\tEpisode Return: 22.407485646901094\tAverage Episode Return: 179.7669076151757\tEvaluator Episode Return: 184.31672672314397\n",
            "Episode: 17000\tEpisode Return: 300.06262775642904\tAverage Episode Return: 144.45078351217362\tEvaluator Episode Return: 123.43345959653348\n",
            "Episode: 17100\tEpisode Return: 54.43779278145979\tAverage Episode Return: 141.92185956635848\tEvaluator Episode Return: 114.27338275109503\n",
            "Episode: 17200\tEpisode Return: 300.09850995141517\tAverage Episode Return: 220.79939302483405\tEvaluator Episode Return: 178.49446597534202\n",
            "Episode: 17300\tEpisode Return: 264.4296507381116\tAverage Episode Return: 253.79613455142393\tEvaluator Episode Return: 215.5631413593489\n",
            "Episode: 17400\tEpisode Return: 264.9342358709898\tAverage Episode Return: 271.4462036742462\tEvaluator Episode Return: 270.02274481348513\n",
            "Episode: 17500\tEpisode Return: 273.0958527177621\tAverage Episode Return: 223.91186618401406\tEvaluator Episode Return: 207.14046933120053\n",
            "Episode: 17600\tEpisode Return: 30.293289113446264\tAverage Episode Return: 221.24011150289078\tEvaluator Episode Return: 252.91947310190267\n",
            "Episode: 17700\tEpisode Return: 27.03599609792657\tAverage Episode Return: 231.839049525549\tEvaluator Episode Return: 225.30585806972667\n",
            "Episode: 17800\tEpisode Return: 283.3760484052458\tAverage Episode Return: 217.4351611285801\tEvaluator Episode Return: 262.16324058122984\n",
            "Episode: 17900\tEpisode Return: 265.44960255926514\tAverage Episode Return: 249.21004377231694\tEvaluator Episode Return: 228.71764513155603\n",
            "Episode: 18000\tEpisode Return: 56.22771214927826\tAverage Episode Return: 184.21457640172687\tEvaluator Episode Return: 247.49664026344152\n",
            "Episode: 18100\tEpisode Return: 279.8335414238843\tAverage Episode Return: 249.95320801302154\tEvaluator Episode Return: 212.79844841379796\n",
            "Episode: 18200\tEpisode Return: 311.92175842593144\tAverage Episode Return: 227.21641784910676\tEvaluator Episode Return: 226.32346345775568\n",
            "Episode: 18300\tEpisode Return: 274.9837432802859\tAverage Episode Return: 256.37414151826715\tEvaluator Episode Return: 261.14990582464054\n",
            "Episode: 18400\tEpisode Return: 33.86300839092104\tAverage Episode Return: 240.04886037571163\tEvaluator Episode Return: 225.7948266312735\n",
            "Episode: 18500\tEpisode Return: 60.802802224800416\tAverage Episode Return: 231.66708702341413\tEvaluator Episode Return: 181.0873941982389\n",
            "Episode: 18600\tEpisode Return: 281.0958884070355\tAverage Episode Return: 236.39806486712547\tEvaluator Episode Return: 176.558236569173\n",
            "Episode: 18700\tEpisode Return: 245.07777440881728\tAverage Episode Return: 250.44976941899395\tEvaluator Episode Return: 234.75346441183086\n",
            "Episode: 18800\tEpisode Return: 254.80853564694422\tAverage Episode Return: 227.28939874777816\tEvaluator Episode Return: 251.64277686020858\n",
            "Episode: 18900\tEpisode Return: 262.9404933755428\tAverage Episode Return: 233.6804901592749\tEvaluator Episode Return: 226.07625204182673\n",
            "Episode: 19000\tEpisode Return: 256.3687114814846\tAverage Episode Return: 247.44053348002723\tEvaluator Episode Return: 244.00245203977616\n",
            "Episode: 19100\tEpisode Return: 295.81673847906507\tAverage Episode Return: 247.25309488920985\tEvaluator Episode Return: 283.37665814263806\n",
            "Episode: 19200\tEpisode Return: 288.04616533776834\tAverage Episode Return: 219.2031816793007\tEvaluator Episode Return: 223.21614000931172\n",
            "Episode: 19300\tEpisode Return: 270.05498130170446\tAverage Episode Return: 198.72058522978512\tEvaluator Episode Return: 177.45528273256343\n",
            "Episode: 19400\tEpisode Return: 291.07624017004593\tAverage Episode Return: 239.84375608674264\tEvaluator Episode Return: 209.77602123219395\n",
            "Episode: 19500\tEpisode Return: -15.177580156225105\tAverage Episode Return: 185.05766481437635\tEvaluator Episode Return: 192.5235766416494\n",
            "Episode: 19600\tEpisode Return: -32.86358613191392\tAverage Episode Return: 238.45491464855726\tEvaluator Episode Return: 152.79829966219546\n",
            "Episode: 19700\tEpisode Return: 285.9051042283013\tAverage Episode Return: 268.0447690618009\tEvaluator Episode Return: 229.02247550329494\n",
            "Episode: 19800\tEpisode Return: 304.4645816211136\tAverage Episode Return: 239.4069613543282\tEvaluator Episode Return: 268.3715318376923\n",
            "Episode: 19900\tEpisode Return: 236.4546296651631\tAverage Episode Return: 194.58408367682878\tEvaluator Episode Return: 213.51554060781137\n",
            "Episode: 20000\tEpisode Return: 236.51478253752506\tAverage Episode Return: 212.85404351649572\tEvaluator Episode Return: 210.3807882833402\n",
            "Episode: 20100\tEpisode Return: 283.8762910359836\tAverage Episode Return: 248.89459989206284\tEvaluator Episode Return: 242.4501951540204\n",
            "Episode: 20200\tEpisode Return: 20.63788107297043\tAverage Episode Return: 234.99282250409925\tEvaluator Episode Return: 215.1888044866439\n",
            "Episode: 20300\tEpisode Return: 242.10785218921077\tAverage Episode Return: 226.4552649443517\tEvaluator Episode Return: 268.628060637763\n",
            "Episode: 20400\tEpisode Return: 261.47583076128535\tAverage Episode Return: 245.94713533570444\tEvaluator Episode Return: 242.55408683264582\n",
            "Episode: 20500\tEpisode Return: 19.16088584620431\tAverage Episode Return: 154.09257011599556\tEvaluator Episode Return: 199.03738439977474\n",
            "Episode: 20600\tEpisode Return: -7.906418891240335\tAverage Episode Return: 258.00936117220454\tEvaluator Episode Return: 269.18495827277695\n",
            "Episode: 20700\tEpisode Return: 51.75262736455744\tAverage Episode Return: 240.7885043019061\tEvaluator Episode Return: 254.01189608575274\n",
            "Episode: 20800\tEpisode Return: 256.3788285960856\tAverage Episode Return: 254.70817146442647\tEvaluator Episode Return: 216.2494164272492\n",
            "Episode: 20900\tEpisode Return: 261.98954034709635\tAverage Episode Return: 267.5899507986833\tEvaluator Episode Return: 247.60832732879166\n",
            "Episode: 21000\tEpisode Return: 268.60875835380153\tAverage Episode Return: 202.4894902990381\tEvaluator Episode Return: 199.99163069921556\n",
            "Episode: 21100\tEpisode Return: 65.9713167272285\tAverage Episode Return: 171.60964945188528\tEvaluator Episode Return: 157.9270152359729\n",
            "Episode: 21200\tEpisode Return: 269.170237137355\tAverage Episode Return: 271.4702163884723\tEvaluator Episode Return: 131.97657546373244\n",
            "Episode: 21300\tEpisode Return: 64.12380150463468\tAverage Episode Return: 228.20953434439267\tEvaluator Episode Return: 202.6970815309083\n",
            "Episode: 21400\tEpisode Return: 248.7057037100377\tAverage Episode Return: 215.00926589752703\tEvaluator Episode Return: 72.29484564568112\n",
            "Episode: 21500\tEpisode Return: 244.72487309191024\tAverage Episode Return: 176.5184371827093\tEvaluator Episode Return: 227.34439905896966\n",
            "Episode: 21600\tEpisode Return: 256.6233025909626\tAverage Episode Return: 229.39105051161397\tEvaluator Episode Return: 211.36206655713795\n",
            "Episode: 21700\tEpisode Return: 286.01735562529115\tAverage Episode Return: 257.52674598854856\tEvaluator Episode Return: 245.21363421606748\n",
            "Episode: 21800\tEpisode Return: 245.83314019193367\tAverage Episode Return: 236.8578263645506\tEvaluator Episode Return: 240.41951107813674\n",
            "Episode: 21900\tEpisode Return: 287.5443241387317\tAverage Episode Return: 245.057837303123\tEvaluator Episode Return: 253.31897296950427\n",
            "Episode: 22000\tEpisode Return: 277.23509443637215\tAverage Episode Return: 253.2471889345888\tEvaluator Episode Return: 249.7193409560676\n",
            "Episode: 22100\tEpisode Return: 49.282774800460345\tAverage Episode Return: 224.15776616591717\tEvaluator Episode Return: 197.58678432635733\n",
            "Episode: 22200\tEpisode Return: 269.7061561672165\tAverage Episode Return: 160.7824039452962\tEvaluator Episode Return: 85.69924489580688\n",
            "Episode: 22300\tEpisode Return: 62.679526382169286\tAverage Episode Return: 151.9267131832128\tEvaluator Episode Return: 198.29798175108044\n",
            "Episode: 22400\tEpisode Return: 277.5657393014402\tAverage Episode Return: 183.53171178347216\tEvaluator Episode Return: 233.61256515545438\n",
            "Episode: 22500\tEpisode Return: 27.655431494905883\tAverage Episode Return: 199.63469355206422\tEvaluator Episode Return: 210.6248396121303\n",
            "Episode: 22600\tEpisode Return: 73.17907958917164\tAverage Episode Return: 245.92220067915255\tEvaluator Episode Return: 250.4376231658153\n",
            "Episode: 22700\tEpisode Return: 283.22126505968646\tAverage Episode Return: 267.0873694735303\tEvaluator Episode Return: 245.31139530537084\n",
            "Episode: 22800\tEpisode Return: 244.15712271413847\tAverage Episode Return: 227.34263191341194\tEvaluator Episode Return: 212.89552787571975\n",
            "Episode: 22900\tEpisode Return: 242.11784185915278\tAverage Episode Return: 262.08223344275194\tEvaluator Episode Return: 276.27608644441733\n",
            "Episode: 23000\tEpisode Return: 270.6886160228937\tAverage Episode Return: 235.05771401945995\tEvaluator Episode Return: 278.67279439070734\n",
            "Episode: 23100\tEpisode Return: 274.3666721529736\tAverage Episode Return: 261.29127573408454\tEvaluator Episode Return: 243.88737036615808\n",
            "Episode: 23200\tEpisode Return: 286.6780301280095\tAverage Episode Return: 260.9482989923479\tEvaluator Episode Return: 177.77096451645656\n",
            "Episode: 23300\tEpisode Return: 254.36863831738643\tAverage Episode Return: 245.10338291010112\tEvaluator Episode Return: 251.78513959274565\n",
            "Episode: 23400\tEpisode Return: 290.32106987942643\tAverage Episode Return: 259.86940176935343\tEvaluator Episode Return: 236.21888691101032\n",
            "Episode: 23500\tEpisode Return: 290.28529542514957\tAverage Episode Return: 268.0923646649307\tEvaluator Episode Return: 277.0277429732995\n",
            "Episode: 23600\tEpisode Return: 266.5708831340413\tAverage Episode Return: 269.9681843593621\tEvaluator Episode Return: 253.93905505636425\n",
            "Episode: 23700\tEpisode Return: 288.49849068542807\tAverage Episode Return: 260.8330442027242\tEvaluator Episode Return: 239.629934898857\n",
            "Episode: 23800\tEpisode Return: 288.08383413019953\tAverage Episode Return: 227.7519250573543\tEvaluator Episode Return: 222.6833516536613\n",
            "Episode: 23900\tEpisode Return: 282.5529140080008\tAverage Episode Return: 198.09896649825677\tEvaluator Episode Return: 196.05731582072377\n",
            "Episode: 24000\tEpisode Return: 257.72262980291566\tAverage Episode Return: 265.50359144693505\tEvaluator Episode Return: 200.25132231196963\n",
            "Episode: 24100\tEpisode Return: 307.81496593122563\tAverage Episode Return: 257.5621266739311\tEvaluator Episode Return: 254.32414549984145\n",
            "Episode: 24200\tEpisode Return: 298.73960524879806\tAverage Episode Return: 252.74319462422378\tEvaluator Episode Return: 242.76071637920387\n",
            "Episode: 24300\tEpisode Return: 61.22858745963808\tAverage Episode Return: 257.47073243570145\tEvaluator Episode Return: 195.08806019957618\n",
            "Episode: 24400\tEpisode Return: 256.9249969559271\tAverage Episode Return: 236.47126889865544\tEvaluator Episode Return: 251.7853932918335\n",
            "Episode: 24500\tEpisode Return: 234.3451948660822\tAverage Episode Return: 261.4489339806534\tEvaluator Episode Return: 266.9346525349992\n",
            "Episode: 24600\tEpisode Return: 282.2611875429403\tAverage Episode Return: 280.39983953359206\tEvaluator Episode Return: 269.2248427727908\n",
            "Episode: 24700\tEpisode Return: 296.0538000520488\tAverage Episode Return: 229.7698054439621\tEvaluator Episode Return: 214.06226826096372\n",
            "Episode: 24800\tEpisode Return: 54.43664864785171\tAverage Episode Return: 209.81808454667407\tEvaluator Episode Return: 200.8194222837456\n",
            "Episode: 24900\tEpisode Return: 298.8556191076366\tAverage Episode Return: 197.49304702778863\tEvaluator Episode Return: 264.4399561056549\n",
            "Episode: 25000\tEpisode Return: 175.0544177497556\tAverage Episode Return: 277.1818962601967\tEvaluator Episode Return: 166.5134393643105\n"
          ]
        }
      ],
      "source": [
        "# Initial learn state\n",
        "REINFORCE_learn_state = REINFORCELearnState(REINFORCE_optim_state)\n",
        "\n",
        "# Run training loop\n",
        "print(\"Starting training. This may take a few minutes to complete.\")\n",
        "episode_returns, evaluator_returns = run_training_loop(\n",
        "                                        env_name,\n",
        "                                        REINFORCE_params,\n",
        "                                        REINFORCE_choose_action_jit,\n",
        "                                        None, # action state not used\n",
        "                                        REINFORCE_learn_jit,\n",
        "                                        REINFORCE_learn_state,\n",
        "                                        REINFORCE_memory,\n",
        "                                        num_episodes=25001,\n",
        "                                        learn_steps_per_episode = 4,                # this has changed\n",
        "                                        video_subdir=\"Lunalanderreinforce\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGuIaPDxZQBu",
        "outputId": "2bdf3311-0d50-4b73-f379-350617f0ac14"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "save_model_parameters(REINFORCE_params, \"./ass2b/learned_params.pkl\")\n",
        "save_episode_returns(episode_returns, file_name=\"./ass2b/episode_returns.pkl\")\n",
        "# Plot the episode returns\n",
        "plt.plot(range(len(episode_returns)), episode_returns)  #Corrected-the-plot-call\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Episode Return\")\n",
        "plt.title(\"REINFORCE\")\n",
        "plt.savefig('./ass2b/llreinforce_loss.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "0dpxn9bnZ_hM",
        "outputId": "16154681-88bc-462e-d319-29503c51e89a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=400 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#@title Visualise Policy {display-mode: \"form\"}\n",
        "#@markdown Choose an episode number that is a multiple of 100 and less than or equal to 1000, and **run this cell**.\n",
        "\n",
        "episode_number = 1750 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "eval_episode_number = int(episode_number / 100 * 8)\n",
        "video_path =\"/content/rl-video-episode-2500.mp4\"\n",
        "\n",
        "\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV3YG7QOZD-B"
      },
      "source": [
        "## **Now... back to earth!**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/1194/1*Dj2fkRjrMA0w9E-PuyETdg.gif\" width=\"60%\" />\n",
        "</center>\n",
        "\n",
        "Once you have successfully solved CartPole using REINFORCE, you should use what you have learned to help Steve land safely back on earth!\n",
        "\n",
        "You will again use the (now think \"earthLander\") [LunarLander](https://www.gymlibrary.ml/environments/box2d/lunar_lander/) environment. As last time, go to the start of the notebook and replace the environment with LunarLander by replacing `env = gym.make(\"CartPole-v1\")` with env = `gym.make(\"LunarLander-v2\")`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf2J1SvuwDMw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f35138c66f99be0fd7a1210bb4aa94a6fbaa5f29d51ad43aec0e0ea0ff050f0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}